# -*- coding: utf-8 -*-
"""Project_pertama_ml_dicoding.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FAD_6Lv1rnkTs5mEBlg87I5eTtbrsgmS

# SPKU Pencemaran Udara di DKI Jakarta tahun 2021

## Problem Statement
The air in Indonesia, especially DKI Jakarta has poor quality, it can be seen that the cause is the large number of motorized vehicle activities outside the room, causing pollution to increase.

In this project, we try to predict whether an air has a `healthy` or `unhealthy` quality

To achieve our goal, we use a `Machine Learning` model to classify our datasets in order to predict the air quality.

To evaluate the performance of the model, we use metric scores in the form of accuracy, precision, recall, and f1 score, but focus more on the f1-score, as well as the use of a confusion matrix.

### Acknowledge
The data we take can be seen from [Jakarta Open Data](https://data.jakarta.go.id/dataset/indeks-standar-pencemaran-udara-ispu-tahun-2021)

## Combining dataset each month
"""

import pandas as pd
import numpy as np

df_januari = pd.read_csv('https://raw.githubusercontent.com/DnYAlv/Intelligent_System/main/ML_Final_project/Dataset/Raw_Data/indeks-standar-pencemar-udara-di-spku-bulan-januari-tahun-2021.csv')
df_januari.columns =['tanggal', 'stasiun', 'pm10', 'pm25', 'so2', 'co', 'o3', 'no2', 'max',
       'critical', 'categori']

df_februari = pd.read_csv('https://raw.githubusercontent.com/DnYAlv/Intelligent_System/main/ML_Final_project/Dataset/Raw_Data/indeks-standar-pencemar-udara-di-spku-bulan-februari-tahun-2021.csv')
df_februari.columns =['tanggal', 'stasiun', 'pm10', 'pm25', 'so2', 'co', 'o3', 'no2', 'max',
       'critical', 'categori'] 

df_maret = pd.read_csv('https://raw.githubusercontent.com/DnYAlv/Intelligent_System/main/ML_Final_project/Dataset/Raw_Data/indeks-standar-pencemar-udara-di-spku-bulan-maret-tahun-2021.csv')
df_maret.columns = ['tanggal', 'stasiun', 'pm10', 'pm25', 'so2', 'co', 'o3', 'no2', 'max',
       'critical', 'categori']

df_april = pd.read_csv('https://raw.githubusercontent.com/DnYAlv/Intelligent_System/main/ML_Final_project/Dataset/Raw_Data/indeks-standar-pencemar-udara-di-spku-bulan-april-tahun-2021.csv')
df_april.columns = ['tanggal', 'stasiun', 'pm10', 'pm25', 'so2', 'co', 'o3', 'no2', 'max',
       'critical', 'categori']

df_mei = pd.read_csv('https://raw.githubusercontent.com/DnYAlv/Intelligent_System/main/ML_Final_project/Dataset/Raw_Data/indeks-standar-pencemar-udara-di-spku-bulan-mei-tahun-2021.csv')
df_mei.columns = ['tanggal', 'stasiun', 'pm10', 'pm25', 'so2', 'co', 'o3', 'no2', 'max',
       'critical', 'categori']

df_juni = pd.read_csv('https://raw.githubusercontent.com/DnYAlv/Intelligent_System/main/ML_Final_project/Dataset/Raw_Data/indeks-standar-pencemar-udara-di-spku-bulan-juni-tahun-2021.csv')
df_juni.columns = ['tanggal', 'stasiun', 'pm10', 'pm25', 'so2', 'co', 'o3', 'no2', 'max',
       'critical', 'categori']

df_juli = pd.read_csv('https://raw.githubusercontent.com/DnYAlv/Intelligent_System/main/ML_Final_project/Dataset/Raw_Data/indeks-standar-pencemar-udara-di-spku-bulan-juli-tahun-2021.csv')
df_juli.columns = ['tanggal', 'stasiun', 'pm10', 'pm25', 'so2', 'co', 'o3', 'no2', 'max',
       'critical', 'categori']

df_agustus = pd.read_csv('https://raw.githubusercontent.com/DnYAlv/Intelligent_System/main/ML_Final_project/Dataset/Raw_Data/indeks-standar-pencemar-udara-di-spku-bulan-agustus-tahun-2021.csv')
df_agustus.columns= ['tanggal', 'stasiun', 'pm10', 'pm25', 'so2', 'co', 'o3', 'no2', 'max',
       'critical', 'categori']

df_september = pd.read_csv('https://raw.githubusercontent.com/DnYAlv/Intelligent_System/main/ML_Final_project/Dataset/Raw_Data/indeks-standar-pencemar-udara-di-spku-bulan-september-tahun-2021.csv')
df_september.columns = ['tanggal', 'stasiun', 'pm10', 'pm25', 'so2', 'co', 'o3', 'no2', 'max',
       'critical', 'categori']

df_oktober = pd.read_csv('https://raw.githubusercontent.com/DnYAlv/Intelligent_System/main/ML_Final_project/Dataset/Raw_Data/indeks-standar-pencemar-udara-di-spku-bulan-oktober-tahun-2021.csv')
df_oktober.columns = ['tanggal', 'stasiun', 'pm10', 'pm25', 'so2', 'co', 'o3', 'no2', 'max',
       'critical', 'categori']

df_november = pd.read_csv('https://raw.githubusercontent.com/DnYAlv/Intelligent_System/main/ML_Final_project/Dataset/Raw_Data/indeks-standar-pencemar-udara-di-spku-bulan-november-tahun-2021.csv')
df_november.columns = ['tanggal', 'stasiun', 'pm10', 'pm25', 'so2', 'co', 'o3', 'no2', 'max',
       'critical', 'categori']

df_desember = pd.read_csv('https://raw.githubusercontent.com/DnYAlv/Intelligent_System/main/ML_Final_project/Dataset/Raw_Data/indeks-standar-pencemar-udara-di-spku-bulan-desember-tahun-2021.csv')
df_desember.columns = ['tanggal', 'stasiun', 'pm10', 'pm25', 'so2', 'co', 'o3', 'no2', 'max',
       'critical', 'categori']

df = pd.concat([df_januari,df_februari,df_maret,df_april ,df_mei,df_juni,df_juli ,df_agustus,df_september,
                df_oktober,df_november,df_desember])

df

df.to_csv('SPKU_data_Januari-Desember-2021.csv', index=False)

"""## Importing Libraries"""

# Visualization
import matplotlib.pyplot as plt
import seaborn as sns

# Normalization
from sklearn.preprocessing import MinMaxScaler, StandardScaler, OneHotEncoder

# Splitting
from sklearn.model_selection import train_test_split

# Missing Values
from scipy.stats import mode
from sklearn.impute import KNNImputer

# Metrics
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix

from imblearn.over_sampling import SMOTE

# K Fold
from random import randrange

import warnings
warnings.filterwarnings("ignore")

df = pd.read_csv('https://raw.githubusercontent.com/DnYAlv/Intelligent_System/main/ML_Final_project/Dataset/SPKU_data_Januari-Desember-2021.csv')

df.head()

"""## Exploratory Data Analysis"""

df.info()

"""#### Tanggal"""

df['tanggal']

"""> As we can see, the dtype of this variable is `object` where actually, this variables need to be in timestamp dtype."""

df['tanggal'] = pd.to_datetime(df['tanggal'], format='%Y-%m-%d')
df['tanggal']

"""#### Category based on Month in "Tanggal"
"""

df['tanggal'].dt.strftime('%B')

plt.figure(figsize=(12,8))
sns.countplot(x='categori', hue=df['tanggal'].dt.strftime('%B'), data=df)
plt.title('Category distributions based on month in "Tanggal"')
plt.show()

"""- Seems like mostly distributions of data were in "SEDANG" category, but for "July" people more likely to have a "TIDAK SEHAT" kind of air (polution).

#### Stasiun
"""

sns.countplot(y='stasiun', data=df)
plt.title('"stasiun" category distributions')
plt.show()

"""> Seems like we have a balanced distribution on "stasiun" variables, which is good.

#### Stasiun vs Categori
"""

plt.figure(figsize=(12,8))
sns.countplot(y='stasiun', hue='categori',data=df)
plt.title('Relation between Stasiun and Categori')
plt.show()

"""> "SEDANG" categori dominated most of these categories, but as we can see, stasiun called DK14 (Lubang Buaya) has a high distribution on "TIDAK SEHAT" categori, which means there are a lot of polution in that area (stasiun)

### Data Cleaning
"""

# Modifying nan value
df=df.replace('---',np.nan)
df = df[df['max'] != 'PM25'].reset_index(drop=True)

# Modifying types
df['pm10'] = df['pm10'].astype(str).astype(float)
df['pm25'] = df['pm25'].astype(str).astype(float)
df['so2'] = df['so2'].astype(str).astype(float)
df['co'] = df['co'].astype(str).astype(float)
df['o3'] = df['o3'].astype(str).astype(float)
df['no2'] = df['no2'].astype(str).astype(float)
df['max'] = df['max'].astype(str).astype(float)

"""### Numerical Value Distributions"""

cols = ['pm10','pm25','so2','co','o3','no2','max']

fig, ax = plt.subplots(len(cols), 3, figsize=(30,40))
for i in range(len(cols)):
  sns.histplot(x=cols[i], data=df, ax=ax[i][0], kde=True)
  sns.boxplot(x=cols[i], data=df, ax=ax[i][1])
  sns.violinplot(x=cols[i], data=df, ax=ax[i][2])
  ax[i][1].set_title(cols[i], weight=1000)

plt.suptitle('Distributions On Numerical Value Variables', size='xx-large', weight=1000)
plt.show()

"""> There are several variables that have relatively skewed distributions, this information may become handy as soon as we handle missing values.

## Preprocessing

### Missing Values
"""

df.isnull().sum()

"""#### Handling Missing Values
- We are using KNNImputer for missing values
> The idea for using KNNImputer for missing values is that KNN can find the neighbor for that missing values, in other way which means that we can find the **Mean** value taken from k-Nearest Neighbors on that missing values.
"""

imputer = KNNImputer(n_neighbors=3)
temp_arr = imputer.fit_transform(df[['pm10','pm25','so2','co','o3','no2']])

numerical_df_impute = pd.DataFrame({
    'pm10':temp_arr[:,0],
    'pm25':temp_arr[:,1],
    'so2':temp_arr[:,2],
    'co':temp_arr[:,3],
    'o3':temp_arr[:,4],
    'no2':temp_arr[:,5]
})
numerical_df_impute

df.drop(['pm10','pm25','so2','co','o3','no2'],axis=1, inplace=True)

data = pd.merge(df, numerical_df_impute, left_index=True, right_index=True)

data

"""- Filling Missing Value with Mode in "critical" variable"""

data['critical'].fillna(data['critical'].mode()[0], inplace=True)

"""### Remove TIDAK ADA DATA in target variable"""

data = data[data['categori'] != 'TIDAK ADA DATA']
data['categori'].value_counts()

"""### Handling highly dominated Categorical Variables

- Critical Variable
"""

sns.countplot('critical', data=data)
plt.title('Critical distributions')
plt.show()

"""> This variable has a highly dominated category (one category dominate the other), and we should consider remove it"""

for col in data.select_dtypes(include='object').columns.tolist():
    print(data[col].value_counts(normalize=True)*100)
    print('\n')

data.drop('critical', axis=1, inplace=True)

"""### Transforming Categorical Variables
- In this section, we will handle `tanggal` to categorize it each quarter (each 4 months).
"""

data['tanggal'] = data['tanggal'].dt.strftime('%B')

data['tanggal'].unique()

data['tanggal'] = data['tanggal'].map({
    'January':'QUARTER 1',
    'February':'QUARTER 1',
    'March':'QUARTER 1',
    'April':'QUARTER 1',
    'May':'QUARTER 2',
    'June':'QUARTER 2',
    'July':'QUARTER 2',
    'August':'QUARTER 2',
    'September':'QUARTER 3',
    'October':'QUARTER 3',
    'November':'QUARTER 3',
    'December':'QUARTER 3'
})
data['tanggal'].value_counts()

"""### Splitting Dataset
- Train Data (80% (Train Data 80%, Valid Data 20%)) and Unseen Data 20%
"""

X = data.drop('categori',axis=1)
y = data['categori']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)

X_train = X_train.reset_index(drop=True)
X_test = X_test.reset_index(drop=True)
y_train = y_train.reset_index(drop=True)
y_test = y_test.reset_index(drop=True)

print(f'X_train shape {X_train.shape}')
print(f'X_test shape {X_test.shape}')
print(f'y_train shape {y_train.shape}')
print(f'y_test shape {y_test.shape}')

"""### Feature Scaling"""

categorical_cols = [col for col in X_train.select_dtypes(include='object').columns.tolist()]
numerical_cols = [col for col in X_train.columns.tolist() if col not in categorical_cols]
numerical_cols

sc = MinMaxScaler()
X_train_scaled = pd.DataFrame(sc.fit_transform(X_train[numerical_cols]), columns = numerical_cols)
X_test_scaled = pd.DataFrame(sc.transform(X_test[numerical_cols]), columns = numerical_cols)

X_train = pd.concat([X_train_scaled, X_train[categorical_cols]], axis=1)
X_test = pd.concat([X_test_scaled, X_test[categorical_cols]], axis=1)

"""#### ONE HOT ENCODING"""

X_train.select_dtypes(include='object').nunique()

OH_list = ['stasiun', 'tanggal']

# One Hot Encoding

OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False, drop='first')
OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[OH_list]))
OH_cols_test = pd.DataFrame(OH_encoder.transform(X_test[OH_list]))

OH_cols_train.index = X_train.index
OH_cols_test.index = X_test.index

OH_cols_train.columns = OH_encoder.get_feature_names_out()
OH_cols_test.columns = OH_encoder.get_feature_names_out()

num_X_train = X_train.drop(OH_list, axis=1)
num_X_test = X_test.drop(OH_list, axis=1)

OH_X_train = pd.concat([num_X_train, OH_cols_train], axis=1)
OH_X_test = pd.concat([num_X_test, OH_cols_test], axis=1)

"""### Transform Target Variable"""

y_train = y_train.map({
    'TIDAK SEHAT':0,
    'SEDANG':1,
    'BAIK':1
})
y_test = y_test.map({
    'TIDAK SEHAT':0,
    'SEDANG':1,
    'BAIK':1
})

sm = SMOTE(random_state=42)
OH_X_trains, OH_y_trains = sm.fit_resample(OH_X_train, y_train)
OH_X_tests, OH_y_tests = sm.fit_resample(OH_X_test, y_test)

train = pd.concat([OH_X_trains, OH_y_trains], axis=1)
test = pd.concat([OH_X_tests, OH_y_tests], axis=1)

"""### Correlation"""

plt.figure(figsize=(12, 8))
sns.heatmap(data=train.corr(), annot=True)
plt.title('Correlation Matrix')
plt.show()

"""> From the correlation above, we may see some variables that highly correlated with each other, this problem called **Multicolinearity**. This could be a problem since there may be some variables that was affected from other variables. In order to drop this, we need to drop one variable in the highly correlated variables."""

# Defining matrix score to positives (absolute score)
correlation_matrix = data.corr().abs()

# Setting so that correlation matrix shape changed
temp_matrix = correlation_matrix.where(np.triu(np.ones(correlation_matrix.shape), k=1).astype(bool))

# Dropping highly correlation score (> 0.6)
var_drop = [column for column in temp_matrix.columns if any(temp_matrix[column] > 0.6)]
var_drop

"""#### Dropping highly correlated variables"""

train.drop(var_drop,axis=1, inplace=True)
test.drop(var_drop,axis=1, inplace=True)

"""## Modelling

### Splitting Train Data
"""

X = train.drop('categori', axis=1)
y = train['categori']

X_train, X_valid, y_train, y_valid = train_test_split(X,y, test_size=0.2, stratify=y, random_state=42)
X_train = X_train.reset_index(drop=True)
X_valid = X_valid.reset_index(drop=True)
y_train = y_train.reset_index(drop=True)
y_valid = y_valid.reset_index(drop=True)

"""### Logistic Regression with Gradient Descent"""

class LogReg_GD:
    def __init__(self, n_Var):
        self.bias = 0
        self.weight = np.random.randn(n_Var)
    
    def sigmoid_function(self, z):
        return 1/(1+np.exp(-z))

    def predict(self, weight, X, bias):
        y_prediction = self.sigmoid_function(np.array(np.dot(X, weight) + bias))
        return y_prediction

    def cost_function(self, X, y, y_prediction):
        m =  X.shape[0]
        return (-1/m)*np.sum(y*np.log(y_prediction) + (1-y)*np.log(1-y_prediction))
    
    def derivative_weight(self, y_prediction, y, X, learning_rate):
        dw = np.dot((y_prediction - y), X)
        return self.weight - (learning_rate * dw)
    
    def derivative_bias(self, y_prediction, y, learning_rate):
        db = np.sum(y_prediction - y)
        return self.bias - (learning_rate * db)
    
    def gradient_descent(self, X, y, epochs, learning_rate):
        loss = []

        for _ in range(epochs):
            y_prediction = self.predict(self.weight, X, self.bias)
            self.weight = self.derivative_weight(y_prediction, y, X, learning_rate)
            self.bias = self.derivative_bias(y_prediction, y, learning_rate)
            loss.append(self.cost_function(X, y, y_prediction))
        
        return loss

lr_candidate = [0.01, 0.05, 0.1]
loss_list = []

for lr in lr_candidate:
    model = LogReg_GD(X_train.shape[1])
    epochs = 500
    loss = model.gradient_descent(X_train, y_train, epochs, lr)
    print(f'Learning Rate : {lr}')
    print(f'Weight : {model.weight}')
    print(f'Bias : {model.bias}')
    loss_list.append([lr, loss])

plt.figure(figsize=(8, 6))
epochs = 500
for i in range(len(loss_list)):
    plt.plot(np.arange(1, epochs), loss_list[i][1][1:], label=loss_list[i][0])

plt.title('Epochs vs Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()
plt.show()

model = LogReg_GD(X_train.shape[1])
epochs = 500
learning_rate = 0.1
model.gradient_descent(X_train, y_train, epochs, learning_rate)
print(f'Weight : {model.weight}')
print(f'Bias : {model.bias}')

def threshold(y):
    return [1 if i >= 0.5 else 0 for i in y]
y_prediction_probability = model.predict(model.weight, X_valid, model.bias)
y_prediction_threshold = threshold(y_prediction_probability)

"""### Prediction with Logistic Regression with Gradient Descent"""

cf = confusion_matrix(y_valid, y_prediction_threshold)
ax = sns.heatmap(cf, annot=True, linewidth=0.1)

ax.set_title('Confusion Matrix')
ax.set_xlabel('Prediction Values')
ax.set_ylabel('Actual Values')

ax.xaxis.set_ticklabels(['False','True'])
ax.yaxis.set_ticklabels(['False','True'])

plt.show()

TRUTH_VALUE = y_valid
print(f'Accuracy Score: {accuracy_score(TRUTH_VALUE, y_prediction_threshold)}')
print(f'Precision Score: {precision_score(TRUTH_VALUE, y_prediction_threshold)}')
print(f'Recall Score: {recall_score(TRUTH_VALUE, y_prediction_threshold)}')
print(f'F1 Score: {f1_score(TRUTH_VALUE, y_prediction_threshold)}')
print(f'\nClassification Score:\n {classification_report(TRUTH_VALUE, y_prediction_threshold)}')

"""#### Cross Validation using K - Fold
- In this section we will try to get the cross validation score from 5 folds on Logistic Regression - Gradient Descent.
"""

def cross_validation_split(dataset, folds=3):
  dataset_split = list()
  dataset_copy = list(dataset)
  fold_size = int(len(dataset)/folds)
  for i in range(folds):
    fold = list()
    while len(fold) < fold_size:
      index = randrange(len(dataset_copy))
      fold.append(dataset_copy.pop(index))
    dataset_split.append(fold)
  return dataset_split

def threshold(y):
  return [1 if i >= 0.5 else 0 for i in y]

folds = cross_validation_split(np.array(train),5)
list_acc = []
list_prec = []
list_f1 = []
list_rec = []
for i in range(len(folds)):
  folded_valid = pd.DataFrame(folds[i], columns = train.columns.tolist())
  idx = 0
  folded_train = pd.DataFrame(columns = train.columns.tolist())
  for j in range(len(folds)):
    if j != i:
      if idx == 0:
        idx = 1
        folded_train = pd.DataFrame(folds[j], columns = train.columns.tolist())
        continue
      folded_train = folded_train.append(pd.DataFrame(folds[j], columns = train.columns.tolist()))

  model_fold = LogReg_GD(X_train.shape[1])
  epochs = 500
  learning_rate = 0.1
  model_fold.gradient_descent(folded_train.drop('categori',axis=1), folded_train['categori'], epochs, learning_rate)

  fold_pred_prob = model_fold.predict(model_fold.weight, folded_valid.drop('categori',axis=1), model_fold.bias)
  folded_pred = threshold(fold_pred_prob)
  TRUTH_VALUE = folded_valid['categori']
  print(f'=========================================\nFold-{i+1}\n=========================================')
  print(f'Accuracy Score: {accuracy_score(TRUTH_VALUE, folded_pred)}')
  print(f'Precision Score: {precision_score(TRUTH_VALUE, folded_pred)}')
  print(f'Recall Score: {recall_score(TRUTH_VALUE, folded_pred)}')
  print(f'F1 Score: {f1_score(TRUTH_VALUE, folded_pred)}')
  print(f'\nClassification Score:\n {classification_report(TRUTH_VALUE, folded_pred)}')

  list_acc.append(accuracy_score(TRUTH_VALUE, folded_pred))
  list_prec.append(precision_score(TRUTH_VALUE, folded_pred))
  list_rec.append(recall_score(TRUTH_VALUE, folded_pred))
  list_f1.append(f1_score(TRUTH_VALUE, folded_pred))

print("Logistic Regression - Gradient Descent Cross Validation Scores")
print(f'Cross Validation (5 - folds) : (Accuracy) = {np.mean(list_acc)}')
print(f'Cross Validation (5 - folds) : (Precision) = {np.mean(list_prec)}')
print(f'Cross Validation (5 - folds) : (Recall) = {np.mean(list_rec)}')
print(f'Cross Validation (5 - folds) : (F1 - Score) = {np.mean(list_f1)}')

"""### KNN"""

class KNN:
  def __init__(self, k, distance_measure, problem):
    self.k = k
    self.distance_measure = distance_measure
    self.problem = problem

  def distance_function(self,a, b,p):
    
    dimension = len(a)

    # Hamming Distance Measures
    if p == -1:
      distance_hamming = 0
      for i in range(dimension):
        if a[i] != b[i]:
          distance_hamming += 1

      return distance_hamming

    # Minkowski, Euclidian, Manhattan Distance Measures
    distance = 0
    for i in range(dimension):
      distance += abs(a[i] - b[i])**p
    
    distance = distance**(1/p)

    return distance
  
  def predict(self, X_train, X_test, y_train):
    
    predict_answer = []

    if self.distance_measure == 'manhattan':
      p=1
    elif self.distance_measure == 'euclidian':
      p=2
    elif self.distance_measure == 'minkowski':
      p=3
    else:
      p=-1

    for test_data in X_test:
      distances = []

      for t in range(len(X_train)):
        distance = self.distance_function(test_data, X_train[t], p)
        distances.append(distance)

      distances = np.array(distances)

      # Sorting and Voting
      df_sort = np.argsort(distances)[:self.k]
      neighbor = y_train[df_sort]

      if self.problem == 'classification':
        prediction = mode(neighbor)
        prediction = prediction.mode[0]

      elif self.problem == 'regression':
        prediction = np.mean(neighbor)
      
      predict_answer.append(prediction)
    return predict_answer

"""#### Tuning KNN to obtain optimum K value"""

accuracy = []
for k in range(1,30):
  model = KNN(k, 'euclidian', 'classification')
  pred = model.predict(np.array(X_train), np.array(X_valid), np.array(y_train))
  accuracy.append(accuracy_score(y_valid, pred))

plt.figure(figsize=(15,8))
plt.plot(accuracy)
plt.title('K value VS Accuracy')
plt.xticks(ticks=np.arange(0,29), labels=np.arange(1,30))
plt.xlabel('K Value')
plt.ylabel('Accuracy')
plt.show()

"""### Prediction with KNN (K = 1)"""

model_1nn = KNN(1, 'euclidian', 'classification')
pred_1nn = model_1nn.predict(np.array(X_train), np.array(X_valid), np.array(y_train))

cf = confusion_matrix(y_valid, pred_1nn)
ax = sns.heatmap(cf, annot=True, linewidth=0.1)

ax.set_title('Confusion Matrix')
ax.set_xlabel('Prediction Values')
ax.set_ylabel('Actual Values')

ax.xaxis.set_ticklabels(['False','True'])
ax.yaxis.set_ticklabels(['False','True'])

plt.show()

TRUTH_VALUE = y_valid
print(f'Accuracy Score: {accuracy_score(TRUTH_VALUE, pred_1nn)}')
print(f'Precision Score: {precision_score(TRUTH_VALUE, pred_1nn)}')
print(f'Recall Score: {recall_score(TRUTH_VALUE, pred_1nn)}')
print(f'F1 Score: {f1_score(TRUTH_VALUE, pred_1nn)}')
print(f'\nClassification Score:\n {classification_report(TRUTH_VALUE, pred_1nn)}')

"""#### Cross Validation with K-Fold
- We will use 5-fold on KNN models.
"""

folds = cross_validation_split(np.array(train),5)
list_acc = []
list_prec = []
list_f1 = []
list_rec = []
for i in range(len(folds)):
  folded_valid = pd.DataFrame(folds[i], columns = train.columns.tolist())
  idx = 0
  folded_train = pd.DataFrame(columns = train.columns.tolist())
  for j in range(len(folds)):
    if j != i:
      if idx == 0:
        idx = 1
        folded_train = pd.DataFrame(folds[j], columns = train.columns.tolist())
        continue
      folded_train = folded_train.append(pd.DataFrame(folds[j], columns = train.columns.tolist()))

  model_fold = KNN(1, 'euclidian', 'classification')
  folded_pred = model_1nn.predict(np.array(folded_train.drop('categori', axis=1)), np.array(folded_valid.drop('categori', axis=1)), np.array(folded_train['categori']))
  TRUTH_VALUE = folded_valid['categori']
  print(f'=========================================\nFold-{i+1}\n=========================================')
  print(f'Accuracy Score: {accuracy_score(TRUTH_VALUE, folded_pred)}')
  print(f'Precision Score: {precision_score(TRUTH_VALUE, folded_pred)}')
  print(f'Recall Score: {recall_score(TRUTH_VALUE, folded_pred)}')
  print(f'F1 Score: {f1_score(TRUTH_VALUE, folded_pred)}')
  print(f'\nClassification Score:\n {classification_report(TRUTH_VALUE, folded_pred)}')

  list_acc.append(accuracy_score(TRUTH_VALUE, folded_pred))
  list_prec.append(precision_score(TRUTH_VALUE, folded_pred))
  list_rec.append(recall_score(TRUTH_VALUE, folded_pred))
  list_f1.append(f1_score(TRUTH_VALUE, folded_pred))

print("1 - Nearest Neighbors Cross Validation Scores")
print(f'Cross Validation (5 - folds) : (Accuracy) = {np.mean(list_acc)}')
print(f'Cross Validation (5 - folds) : (Precision) = {np.mean(list_prec)}')
print(f'Cross Validation (5 - folds) : (Recall) = {np.mean(list_rec)}')
print(f'Cross Validation (5 - folds) : (F1 - Score) = {np.mean(list_f1)}')

"""### Naive Bayes

"""

class Naive_Bayes:

    def fit(self, X, y):
        self.parameters = {}
        self.priors = {}

        for i in X.columns:
            self.parameters[i] = {}
        
        full_df = pd.concat([X, y], axis=1)
        full_df = full_df.sort_values(by=['categori'])
        self.unique_class = y.unique()

        # Dividing class 1 and 0
        divide_class = {}
        for x in self.unique_class:
            divide_class[x] = full_df[full_df['categori'] == x].loc[:, full_df.columns != 'categori']

        # Finding Mean and Variance
        for i in divide_class:
            for j in divide_class[i]:
                self.parameters[j][i] = self.mean_variance(divide_class[i][j])
        
        # Calculate prior probability each class
        for i in self.unique_class:
            self.priors[i] = len(divide_class[i])/ len(full_df)
    
    def mean_variance(self, df):
        mean = df.mean()
        variance = df.var()
        return {'mean': mean, 'variance': variance}

    def predict(self, X):
        predictions = []

        for i in range(len(X)):
            full_class_posterior = np.array([])

            for x in self.unique_class:
                posterior_likelihood = 1

                for cols in X.columns:
                    value = X.iloc[i][cols]
                    mean = self.parameters[cols][x]['mean']
                    variance = self.parameters[cols][x]['variance']
                    likelihood = (1 / (np.sqrt(2 * np.pi * variance))) * np.exp(-1 * ((value - mean)**2 / (2 * variance)))
                    posterior_likelihood *= likelihood

                post = posterior_likelihood * self.priors[x]
                full_class_posterior = np.append(full_class_posterior, post)
            predictions.append(self.unique_class[np.argmax(full_class_posterior)])
        return predictions

model = Naive_Bayes()
model.fit(X_train, y_train)

y_valid_pred = model.predict(X_valid)

df_valid = pd.DataFrame({
    'GROUND TRUTH': y_valid,
    'PREDICTIONS': y_valid_pred
})

df_valid

"""### Prediction with Naive Bayes"""

cf = confusion_matrix(y_valid, y_valid_pred)
ax = sns.heatmap(cf, annot=True, linewidth=0.1)

ax.set_title('Confusion Matrix')
ax.set_xlabel('Prediction Values')
ax.set_ylabel('Actual Values')

ax.xaxis.set_ticklabels(['False','True'])
ax.yaxis.set_ticklabels(['False','True'])

plt.show()

TRUTH_VALUE = y_valid
print(f'Accuracy Score: {accuracy_score(TRUTH_VALUE, y_valid_pred)}')
print(f'Precision Score: {precision_score(TRUTH_VALUE, y_valid_pred)}')
print(f'Recall Score: {recall_score(TRUTH_VALUE, y_valid_pred)}')
print(f'F1 Score: {f1_score(TRUTH_VALUE, y_valid_pred)}')
print(f'\nClassification Score:\n {classification_report(TRUTH_VALUE, y_valid_pred)}')

"""#### Cross Validation using K - Fold
- In this section we will try to do Cross Validation on Naive Bayes model
"""

folds = cross_validation_split(np.array(train),5)
list_acc = []
list_prec = []
list_f1 = []
list_rec = []
for i in range(len(folds)):
  folded_valid = pd.DataFrame(folds[i], columns = train.columns.tolist())
  idx = 0
  folded_train = pd.DataFrame(columns = train.columns.tolist())
  for j in range(len(folds)):
    if j != i:
      if idx == 0:
        idx = 1
        folded_train = pd.DataFrame(folds[j], columns = train.columns.tolist())
        continue
      folded_train = folded_train.append(pd.DataFrame(folds[j], columns = train.columns.tolist()))

  model_fold = Naive_Bayes()
  model_fold.fit(folded_train.drop('categori', axis=1), folded_train['categori'])
  folded_pred = model_fold.predict(folded_valid.drop('categori', axis=1))
  TRUTH_VALUE = folded_valid['categori']
  print(f'=========================================\nFold-{i+1}\n=========================================')
  print(f'Accuracy Score: {accuracy_score(TRUTH_VALUE, folded_pred)}')
  print(f'Precision Score: {precision_score(TRUTH_VALUE, folded_pred)}')
  print(f'Recall Score: {recall_score(TRUTH_VALUE, folded_pred)}')
  print(f'F1 Score: {f1_score(TRUTH_VALUE, folded_pred)}')
  print(f'\nClassification Score:\n {classification_report(TRUTH_VALUE, folded_pred)}')

  list_acc.append(accuracy_score(TRUTH_VALUE, folded_pred))
  list_prec.append(precision_score(TRUTH_VALUE, folded_pred))
  list_rec.append(recall_score(TRUTH_VALUE, folded_pred))
  list_f1.append(f1_score(TRUTH_VALUE, folded_pred))

print("Naive Bayes Cross Validation Scores")
print(f'Cross Validation (5 - folds) : (Accuracy) = {np.mean(list_acc)}')
print(f'Cross Validation (5 - folds) : (Precision) = {np.mean(list_prec)}')
print(f'Cross Validation (5 - folds) : (Recall) = {np.mean(list_rec)}')
print(f'Cross Validation (5 - folds) : (F1 - Score) = {np.mean(list_f1)}')

"""### Building Final Model
> It seems like Logistic Regression with Gradient Descent able to perform really well on our dataset, let's build our final model with that.
"""

final_model = LogReg_GD(X_train.shape[1])
epochs = 500
learning_rate = 0.1
final_model.gradient_descent(X_train, y_train, epochs, learning_rate)
print(f'Weight : {final_model.weight}')
print(f'Bias : {final_model.bias}')

def threshold(y):
    return [1 if i >= 0.5 else 0 for i in y]

"""## Using Model on Unseen Data"""

unseen_X = test.drop('categori',axis=1)
unseen_y = test['categori']

unseen_pred_prob = final_model.predict(final_model.weight, unseen_X, final_model.bias)
unseen_pred = threshold(unseen_pred_prob)
TRUTH_VALUE = unseen_y
print(f'Accuracy Score: {accuracy_score(TRUTH_VALUE, unseen_pred)}')
print(f'Precision Score: {precision_score(TRUTH_VALUE, unseen_pred)}')
print(f'Recall Score: {recall_score(TRUTH_VALUE, unseen_pred)}')
print(f'F1 Score: {f1_score(TRUTH_VALUE, unseen_pred)}')
print(f'\nClassification Score:\n {classification_report(TRUTH_VALUE, unseen_pred)}')

"""## Conclusion
> As we can see, **Logistic Regression with Gradient Descent** model can perform very well both on validation data and especially, unseen dataset, which means that this model is **Not Overfitting** which is good. This performance proven by both **Cross Validation** Method and in *unseen dataset*, we can see that this model can achieve a perfect score (100% Accuracy).

## Recommendation
> It would be better if we get more data, to see whether our model can still perform well even with bigger data
"""

import pickle
filename = 'finalized_model.sav'
pickle.dump(model, open(filename, 'wb'))